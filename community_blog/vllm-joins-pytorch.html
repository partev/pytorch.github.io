<p>We’re thrilled to announce that the <a href="https://github.com/vllm-project/vllm">vLLM project</a> has become a PyTorch ecosystem project, and joined the PyTorch ecosystem family!</p>

<p>Running large language models (LLMs) is both resource-intensive and complex, especially as these models scale to hundreds of billions of parameters. That’s where vLLM comes in — a high-throughput, memory-efficient inference and serving engine designed for LLMs.</p>
